{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a783144e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'ul'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b9226ea20e1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'src'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mrequirements\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"css-1t5f0fr\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mul\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mrespon_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\py3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2252\u001b[0m         \u001b[1;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2253\u001b[0m         raise AttributeError(\n\u001b[1;32m-> 2254\u001b[1;33m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2255\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'ul'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "##import required libraries\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from itertools import zip_longest\n",
    "\n",
    "page_num =0\n",
    "while True:\n",
    "    \n",
    "## grap the data using requests library  \n",
    "    result = requests.get(f\"https://wuzzuf.net/search/jobs/?a=hpb%3D5&q=data%20engineer&start={page_num}\")\n",
    "\n",
    "    src = result.content\n",
    "## create object from Beautifulsoup to parse content \n",
    "    soup = BeautifulSoup(src,'lxml')\n",
    "    job_name = []\n",
    "    location = []\n",
    "    company_name = []\n",
    "    job_skill =[]\n",
    "    links =[]\n",
    "    responsablities = []\n",
    "## find the elemants contain info that we need\n",
    "    job_names = soup.find_all('h2',{'class':'css-m604qf'})\n",
    "    locations = soup.find_all('span',{'class':'css-5wys0k'})\n",
    "    company_names =  soup.find_all('a',{'class':'css-17s97q8'})\n",
    "    job_skills = soup.find_all('div',{'class':'css-y4udm8'})\n",
    "    linkss = soup.find_all('a', href = True)\n",
    "## loop over returned list to extract needed ifo into other lists\n",
    "    for i in range(len(job_names)):\n",
    "        job_name.append(job_names[i].text)\n",
    "        links.append(soup.find('a').attrs['href'] )\n",
    "        location.append(locations[i].text)\n",
    "        company_name.append(company_names[i].text)\n",
    "        job_skill.append(job_skills[i].text)\n",
    "\n",
    "    for link in links:\n",
    "        result = requests.get(link)\n",
    "        src = result.content\n",
    "        soup = BeautifulSoup('src','lxml')\n",
    "        requirements= soup.find_all('div',{\"class\":\"css-1t5f0fr\"}).ul\n",
    "\n",
    "    respon_text = ''\n",
    "    for li in requirements.find_all('li'):\n",
    "            respon_text += li.text\n",
    "\n",
    "    responsablities.append(respon_text)\n",
    "\n",
    "    page_num +=1\n",
    "    print(\"page switched\")\n",
    "\n",
    "    page_limit = int(soup.find('strong').text)\n",
    "    if (page_num > page_limit // 15):\n",
    "        break\n",
    "    \n",
    "data =[job_name,company_name,job_skill,locations,links,responsablities]\n",
    "exported = zip_longest(*data)\n",
    "\n",
    "## create csv file and fill data into it\n",
    "with open(r'C:\\Users\\Options\\Desktop\\work.xlsx','w') as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerow(['job_name','company_name','job_skill','locations','links','responsablities'])\n",
    "    wr.writerows(exported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428c1c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81543b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
